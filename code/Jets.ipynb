{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed = 777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "Download link (19Gb): http://mlphysics.ics.uci.edu/data/hepjets/images/test_no_pile_5000000.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Get data from http://www.igb.uci.edu/~pfbaldi/physics/data/hepjets/highlevel/\n",
    "\n",
    "f = h5py.File(\"hepjets/test_no_pile_5000000.h5\", \"r\")\n",
    "X_no_pile = f[\"features\"].value\n",
    "y_no_pile = f[\"targets\"].value.ravel()\n",
    "\n",
    "f = h5py.File(\"hepjets/test_pile_5000000.h5\", \"r\")\n",
    "X_pile = f[\"features\"].value\n",
    "y_pile = f[\"targets\"].value.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.vstack((X_no_pile, X_pile))\n",
    "y = np.concatenate((y_no_pile, y_pile)).ravel()\n",
    "z = np.zeros(len(X))\n",
    "z[len(X_no_pile):] = 1\n",
    "\n",
    "strates = np.zeros(len(X))\n",
    "strates[(y==0)&(z==0)]=0\n",
    "strates[(y==0)&(z==1)]=1\n",
    "strates[(y==1)&(z==0)]=2\n",
    "strates[(y==1)&(z==1)]=3\n",
    "\n",
    "from keras.utils import np_utils\n",
    "z = np_utils.to_categorical(z.astype(np.int))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tf = StandardScaler()\n",
    "X = tf.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(X, y, z, test_size=25000, random_state=1, stratify=strates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:150000]\n",
    "y_train = y_train[:150000]\n",
    "z_train = z_train[:150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('jets-pile.pickle', 'wb') as file:\n",
    "    pickle.dump([X_train, X_test, y_train, y_test, z_train, z_test], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(X.shape[1],))\n",
    "Dx = Dense(64, activation=\"tanh\")(inputs)\n",
    "Dx = Dense(64, activation=\"relu\")(Dx)\n",
    "Dx = Dense(64, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(inputs=[inputs], outputs=[Dx])\n",
    "\n",
    "Rx = D(inputs)\n",
    "Rx = Dense(64, activation=\"relu\")(Rx)\n",
    "Rx = Dense(64, activation=\"relu\")(Rx)\n",
    "Rx = Dense(64, activation=\"relu\")(Rx)\n",
    "Rx = Dense(z.shape[1], activation=\"softmax\")(Rx)\n",
    "R = Model(inputs=[inputs], outputs=[Rx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "import keras.backend as K\n",
    "\n",
    "lam = 1.0\n",
    "\n",
    "def make_loss_D(c):\n",
    "    def loss_D(y_true, y_pred):\n",
    "        return c * K.binary_crossentropy(y_true, y_pred)\n",
    "    return loss_D\n",
    "\n",
    "def make_loss_R(c):\n",
    "    def loss_R(z_true, z_pred):\n",
    "        return c * K.categorical_crossentropy(z_true, z_pred)\n",
    "    return loss_R\n",
    "\n",
    "opt_D = Adam()\n",
    "D.compile(loss=[make_loss_D(c=1.0)], optimizer=opt_D)\n",
    "\n",
    "opt_DRf = SGD(momentum=0) \n",
    "DRf = Model(inputs=[inputs], outputs=[D(inputs), R(inputs)])\n",
    "DRf.compile(loss=[make_loss_D(c=1.0), \n",
    "                  make_loss_R(c=-lam)],   # compare with c=0.0, ie. when no there is no adversary\n",
    "            optimizer=opt_DRf)\n",
    "\n",
    "opt_DfR = SGD(momentum=0)\n",
    "DfR = Model(inputs=[inputs], outputs=[R(inputs)])\n",
    "DfR.compile(loss=[make_loss_R(c=1.0)], \n",
    "            optimizer=opt_DfR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DfR.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "See `jets.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMS plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_AMS1(pred,Y,Z, label):\n",
    "    x00 = np.sort(pred[((Y==0)*(Z==0))].flatten())\n",
    "    x01 = np.sort(pred[((Y==0)*(Z==1))].flatten())\n",
    "    x10 = np.sort(pred[((Y==1)*(Z==0))].flatten())\n",
    " \n",
    "    n_points = 100\n",
    "    AMS1 = np.zeros(n_points)\n",
    "    all_ns = np.zeros(n_points)\n",
    "    all_nb = np.zeros(n_points)\n",
    "    all_nb1 = np.zeros(n_points)\n",
    "    all_sigb = np.zeros(n_points)\n",
    "\n",
    "    cuts = np.zeros(n_points)\n",
    "    sig_eff = np.zeros(n_points)\n",
    "    ns_tot = x10.shape[0]\n",
    "    \n",
    "    for i, c_i in enumerate(np.linspace(0.0, 1.0, n_points)):\n",
    "        cuts[i] = c_i\n",
    "        \n",
    "        ns = (100 / x10.size) * np.count_nonzero(x10 > c_i) \n",
    "        nb = (1000 / x00.size) * np.count_nonzero(x00 > c_i) \n",
    "        nb1 = (1000 / x01.size) * np.count_nonzero(x01 > c_i) \n",
    "        sig_b = 1.0 * np.abs(nb - nb1) \n",
    "        \n",
    "        b0 = 0.5 * (nb - sig_b ** 2 + ((nb - sig_b ** 2) ** 2 + 4 * (ns + nb) * (sig_b ** 2)) ** 0.5)\n",
    "        AMS1[i] = (2.0 * ((ns + nb) * np.log((ns + nb) / b0) - ns - nb + b0) + ((nb - b0) / sig_b) ** 2) ** 0.5\n",
    "        \n",
    "        all_ns[i] = ns\n",
    "        all_nb[i] = nb\n",
    "        all_nb1[i] = nb\n",
    "        all_sigb[i] = sig_b\n",
    "        \n",
    "        sig_eff[i] = (1.0*ns) / ns_tot\n",
    "        \n",
    "    return cuts, AMS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "indices = np.random.permutation(len(X))\n",
    "indices = indices[:5000000]\n",
    "\n",
    "for lam, c in zip([0.0], [\"r\"]):\n",
    "    ams = []\n",
    "\n",
    "    for f in glob.glob(\"D-%.4f-*.h5\" % lam):\n",
    "        print(f)\n",
    "        D.load_weights(f)\n",
    "        cuts, a = plot_AMS1(D.predict(X[indices]), y[indices], z[indices, 1], f)\n",
    "        ams.append(a)\n",
    "        \n",
    "    mu = np.mean(ams, axis=0) \n",
    "    std = np.std(ams, axis=0)\n",
    "    plt.plot(cuts, mu, label=r\"$\\lambda=%d|Z=0$\" % lam, c=c)\n",
    "    plt.fill_between(cuts, mu+std, mu-std, color=c, alpha=0.1)\n",
    "    \n",
    "for lam, c in zip([0.0, 1.0, 10, 500.], [\"g\", \"b\", \"c\", \"orange\", \"y\", \"grey\", \"k\"]):\n",
    "    ams = []\n",
    "\n",
    "    for f in glob.glob(\"y=0/D-%.4f-*.h5\" % lam):\n",
    "        print(f)\n",
    "        D.load_weights(f)\n",
    "        cuts, a = plot_AMS1(D.predict(X[indices]), y[indices], z[indices, 1], f)\n",
    "        ams.append(a)\n",
    "        \n",
    "    mu = np.mean(ams, axis=0) \n",
    "    std = np.std(ams, axis=0)\n",
    "    plt.plot(cuts, mu, label=r\"$\\lambda=%d$\" % lam, c=c)\n",
    "    plt.fill_between(cuts, mu+std, mu-std, color=c, alpha=0.1)\n",
    "    \n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylabel(\"AMS\")\n",
    "plt.xlabel(\"threshold on $f(X)$\")\n",
    "plt.grid()\n",
    "plt.savefig(\"ams.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
